import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import LabelEncoder  # Para convertir la variable categ√≥rica

# Cargar el dataset
df = pd.read_csv("resultados.csv")  

# Verificar nombres de columnas
print("\nColumnas en el dataset:", df.columns)

# Asegurar que las columnas no tengan espacios extra
df.columns = df.columns.str.strip()

# Verificar valores √∫nicos en la columna 'NObeyesdad'
print("\nValores √∫nicos en 'NObeyesdad':", df["NObeyesdad"].unique())

# Convertir la variable categ√≥rica 'NObeyesdad' a n√∫meros
encoder = LabelEncoder()
df["NObeyesdad_encoded"] = encoder.fit_transform(df["NObeyesdad"])

# Mostrar c√≥mo se codificaron las categor√≠as
print("\nConversi√≥n de categor√≠as:")
for categoria, codigo in zip(encoder.classes_, encoder.transform(encoder.classes_)):
    print(f"{categoria}: {codigo}")

# Seleccionar variables
X = df[['Weight']].values  # Variable independiente (peso)
y = df[['NObeyesdad_encoded']].values  # Variable dependiente (nivel de obesidad en n√∫meros)

# Crear y entrenar el modelo de regresi√≥n lineal
model = LinearRegression()
model.fit(X, y)

# Hacer predicciones
y_pred = model.predict(X)

# Mostrar coeficientes
print("\nIntercepto (w‚ÇÄ):", model.intercept_[0])
print("Pendiente (w‚ÇÅ):", model.coef_[0][0])

# Graficar la regresi√≥n
plt.scatter(X, y, color='blue', label='Datos reales')  # Puntos originales
plt.plot(X, y_pred, color='red', label='L√≠nea de regresi√≥n')  # L√≠nea de regresi√≥n
plt.title('Regresi√≥n Lineal Simple: Peso vs. Nivel de Obesidad (Codificado)')
plt.xlabel('Peso (kg)')
plt.ylabel('Nivel de Obesidad')
plt.legend()
plt.grid(True)
plt.show()


#REGRESION MULTIPLE

# üìå 2. Calcular IMC y PBF
df["IMC"] = df["Weight"] / (df["Height"] ** 2)

# Convertir Gender a num√©rico: 1 para hombres, 0 para mujeres
df["Gender"] = df["Gender"].map({"Male": 1, "Female": 0})  

df["PBF"] = (
    (1.20 * df["IMC"]) +
    (0.23 * df["Age"]) -
    (10.8 * df["Gender"]) -
    5.4
)

# üìå 4. Seleccionar variables para la regresi√≥n
X = df[['Weight', 'IMC', 'PBF']].values  # Variables independientes
y = df['NObeyesdad_encoded'].values  # Variable dependiente

# üìå 5. Crear el modelo y ajustarlo a los datos
model = LinearRegression()
model.fit(X, y)

# Hacer predicciones
y_pred = model.predict(X)

# üìå 6. Mostrar coeficientes
print("Intercepto (w‚ÇÄ):", model.intercept_)
print("Coeficientes (w‚ÇÅ, w‚ÇÇ, w‚ÇÉ):", model.coef_)

# üìå 7. Mostrar pares de puntos
print("\nPares de puntos (Weight, IMC, PBF, NObeyesdad):")
for (w, imc, pbf), yi in zip(X, y):
    print(f"({w:.2f}, {imc:.2f}, {pbf:.2f}, {yi:.2f})")

# üìå 8. Visualizaci√≥n de la regresi√≥n con planos separados (solo con 2 variables independientes)
fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111, projection='3d')

# Puntos originales
ax.scatter(X[:, 0], X[:, 1], y, color='blue', label='Datos originales')

# Crear una malla para la superficie de predicci√≥n
x1_grid, x2_grid = np.meshgrid(
    np.linspace(min(X[:, 0]), max(X[:, 0]), 10),
    np.linspace(min(X[:, 1]), max(X[:, 1]), 10)
)

# Calcular los valores predichos en la malla usando solo Weight e IMC
y_pred_grid = (model.intercept_ +
               model.coef_[0] * x1_grid +
               model.coef_[1] * x2_grid)

# Dibujar la superficie de predicci√≥n
ax.plot_surface(x1_grid, x2_grid, y_pred_grid, color='red', alpha=0.5)

# Etiquetas y t√≠tulo
ax.set_title('Regresi√≥n Lineal M√∫ltiple: Peso, IMC y Nivel de Obesidad')
ax.set_xlabel('Peso (kg)')
ax.set_ylabel('IMC')
ax.set_zlabel('Nivel de Obesidad')
ax.legend(["Datos originales", "Plano de predicciones"])

plt.show()